{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "#os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"\n",
    "                                                ] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDen</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sn %</th>\n",
       "      <th>pH</th>\n",
       "      <th>C2H4</th>\n",
       "      <th>CO</th>\n",
       "      <th>H2</th>\n",
       "      <th>EtoH</th>\n",
       "      <th>FORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>3.3</td>\n",
       "      <td>80</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>3.2</td>\n",
       "      <td>50</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>3.1</td>\n",
       "      <td>10</td>\n",
       "      <td>14.05</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>14.05</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cDen  Pot  Sn %     pH  C2H4  CO  H2  EtoH  FORM\n",
       "0   150  3.5   100  14.05     0  23  12     0    61\n",
       "1   150  3.3    80  14.05     0  23   7     0    66\n",
       "2   150  3.2    50  14.05     0  34   5     3    52\n",
       "3   150  3.1    10  14.05     1  42   5     2    42\n",
       "4   150  3.0     5  14.05     4  48   5    10    19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../data/data.xlsx')\n",
    "data = data.drop(columns=['S/N'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['cDen', 'Pot', 'Sn %', 'pH']\n",
      "Target:  ['C2H4', 'CO', 'H2', 'EtoH', 'FORM']\n"
     ]
    }
   ],
   "source": [
    "features_col = list(data.columns[:4])\n",
    "target_col = list(data.columns[4:])\n",
    "#target_col = [target_col[0], target_col[2]]\n",
    "print('Features: ', features_col)\n",
    "print('Target: ', target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDen</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sn %</th>\n",
       "      <th>pH</th>\n",
       "      <th>C2H4</th>\n",
       "      <th>CO</th>\n",
       "      <th>H2</th>\n",
       "      <th>EtoH</th>\n",
       "      <th>FORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>3.3</td>\n",
       "      <td>80</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cDen  Pot  Sn %     pH  C2H4    CO    H2  EtoH  FORM\n",
       "0   150  3.5   100  14.05   0.0  0.23  0.12   0.0  0.61\n",
       "1   150  3.3    80  14.05   0.0  0.23  0.07   0.0  0.66"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the data in target columns by 100\n",
    "data[target_col] = data[target_col] / 100\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDen</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sn %</th>\n",
       "      <th>pH</th>\n",
       "      <th>C2H4</th>\n",
       "      <th>CO</th>\n",
       "      <th>H2</th>\n",
       "      <th>EtoH</th>\n",
       "      <th>FORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cDen  Pot  Sn %     pH  C2H4    CO    H2  EtoH  FORM\n",
       "0   150  3.5   1.0  14.05   0.0  0.23  0.12   0.0  0.61\n",
       "1   150  3.3   0.8  14.05   0.0  0.23  0.07   0.0  0.66"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[features_col[2]] = data[features_col[2]] / 100\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDen</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sn %</th>\n",
       "      <th>pH</th>\n",
       "      <th>C2H4</th>\n",
       "      <th>CO</th>\n",
       "      <th>H2</th>\n",
       "      <th>EtoH</th>\n",
       "      <th>FORM</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>118.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>107.6772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>91.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.42</td>\n",
       "      <td>69.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>66.3042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cDen  Pot  Sn %     pH  C2H4    CO    H2  EtoH  FORM    weight\n",
       "0   150  3.5  1.00  14.05  0.00  0.23  0.12  0.00  0.61  118.7100\n",
       "1   150  3.3  0.80  14.05  0.00  0.23  0.07  0.00  0.66  107.6772\n",
       "2   150  3.2  0.50  14.05  0.00  0.34  0.05  0.03  0.52   91.1280\n",
       "3   150  3.1  0.10  14.05  0.01  0.42  0.05  0.02  0.42   69.0624\n",
       "4   150  3.0  0.05  14.05  0.04  0.48  0.05  0.10  0.19   66.3042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pymatgen structure from the data. remember that it's CuSn with Sn fraction in position 2 in features_col\n",
    "import pymatgen.core as pmg\n",
    "\n",
    "def create_structure(Sn_percent):\n",
    "    # create the structure\n",
    "    if Sn_percent <= 1:\n",
    "        base = f'Cu{1-Sn_percent}Sn{Sn_percent}'\n",
    "        comp = pmg.Composition(base)\n",
    "    else:\n",
    "        raise ValueError('Sn percent must be less than or equal to 1')\n",
    "    return comp\n",
    "\n",
    "data['weight'] = data['Sn %'].apply(create_structure).apply(lambda x: x.weight)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDen</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sn %</th>\n",
       "      <th>pH</th>\n",
       "      <th>C2H4</th>\n",
       "      <th>CO</th>\n",
       "      <th>H2</th>\n",
       "      <th>EtoH</th>\n",
       "      <th>FORM</th>\n",
       "      <th>weight</th>\n",
       "      <th>Cu %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>118.7100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>107.6772</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cDen  Pot  Sn %     pH  C2H4    CO    H2  EtoH  FORM    weight  Cu %\n",
       "0   150  3.5   1.0  14.05   0.0  0.23  0.12   0.0  0.61  118.7100   0.0\n",
       "1   150  3.3   0.8  14.05   0.0  0.23  0.07   0.0  0.66  107.6772   0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cu %'] = 1 - data['Sn %']\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C2H4', 'CO', 'H2', 'EtoH', 'FORM']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col += ['weight', 'Cu %']\n",
    "X = data[features_col]\n",
    "y = data[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gp_regression import FixedNoiseGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cDen</th>\n",
       "      <td>35.0</td>\n",
       "      <td>269.171429</td>\n",
       "      <td>119.205824</td>\n",
       "      <td>141.000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>250.0000</td>\n",
       "      <td>350.0000</td>\n",
       "      <td>450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pot</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.500118</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.55000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.1500</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sn %</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.388203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>35.0</td>\n",
       "      <td>12.844000</td>\n",
       "      <td>2.447214</td>\n",
       "      <td>8.020</td>\n",
       "      <td>14.05000</td>\n",
       "      <td>14.0500</td>\n",
       "      <td>14.0500</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>35.0</td>\n",
       "      <td>83.089817</td>\n",
       "      <td>21.414838</td>\n",
       "      <td>63.546</td>\n",
       "      <td>65.20092</td>\n",
       "      <td>69.0624</td>\n",
       "      <td>107.6772</td>\n",
       "      <td>118.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cu %</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.388203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count        mean         std      min        25%       50%       75%  \\\n",
       "cDen     35.0  269.171429  119.205824  141.000  150.00000  250.0000  350.0000   \n",
       "Pot      35.0    3.860000    0.500118    2.800    3.55000    4.0000    4.1500   \n",
       "Sn %     35.0    0.354286    0.388203    0.000    0.03000    0.1000    0.8000   \n",
       "pH       35.0   12.844000    2.447214    8.020   14.05000   14.0500   14.0500   \n",
       "weight   35.0   83.089817   21.414838   63.546   65.20092   69.0624  107.6772   \n",
       "Cu %     35.0    0.645714    0.388203    0.000    0.20000    0.9000    0.9700   \n",
       "\n",
       "           max  \n",
       "cDen    450.00  \n",
       "Pot       4.70  \n",
       "Sn %      1.00  \n",
       "pH       14.05  \n",
       "weight  118.71  \n",
       "Cu %      1.00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import List\n",
    "_VERBOSE = False\n",
    "def get_experimental_bounds(X_columns: List[str], verbose: bool = _VERBOSE) -> Tensor:\n",
    "    \"\"\"Returns bounds of columns in X for mortar mixes.\n",
    "\n",
    "    Args:\n",
    "        X_columns: Names of the columns in the input dataset.\n",
    "        verbose: Whether to print what the lower and upper bounds are set to.\n",
    "\n",
    "    Tensor:\n",
    "        A `2 x d`-dim Tensor of lower and upper mortar bounds for each column of X.\n",
    "    \"\"\"\n",
    "    bounds_dict = {\n",
    "        \"cDen\": (150, 450),  # in grams, as opposed to the original concrete bounds\n",
    "        \"Pot\": (2.8, 4.7),\n",
    "        \"Sn %\": (0, 1),\n",
    "        \"pH\": (8.02, 14.05),\n",
    "        \"weight\": (63.546, 118.71),\n",
    "        \"Cu %\": (0, 1)\n",
    "    }\n",
    "\n",
    "    bounds = torch.tensor([bounds_dict[col] for col in X_columns]).T\n",
    "    if verbose:\n",
    "        print(\"The lower and upper bounds for the respective variables are set to:\")\n",
    "        for col, bound in zip(X_columns, bounds.T):\n",
    "            print(f\"\\t- {col}: [{bound[0].item()}, {bound[1].item()}]\")\n",
    "        print()\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[150.0000,   2.8000,   0.0000,   8.0200,  63.5460,   0.0000],\n",
       "        [450.0000,   4.7000,   1.0000,  14.0500, 118.7100,   1.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = get_experimental_bounds(features_col, verbose=False)\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model(train_x, train_obj):\n",
    "    # define models for objective and constraint\n",
    "    train_x = normalize(train_x, bounds)\n",
    "    models = []\n",
    "    for i in range(train_obj.shape[-1]):\n",
    "        train_y = train_obj[..., i : i + 1]\n",
    "        train_yvar = torch.full_like(train_y, 0.2)\n",
    "        models.append(\n",
    "            FixedNoiseGP(\n",
    "                train_x, train_y, train_yvar, outcome_transform=Standardize(m=1)\n",
    "            )\n",
    "        )\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 6]) torch.Size([35, 5])\n"
     ]
    }
   ],
   "source": [
    "X_torch, y_torch = torch.from_numpy(X.to_numpy()), torch.from_numpy(y.to_numpy())\n",
    "print(X_torch.shape, y_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/MatML/lib/python3.8/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SumMarginalLogLikelihood(\n",
       "   (likelihood): LikelihoodList(\n",
       "     (likelihoods): ModuleList(\n",
       "       (0): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (1): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (2): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (3): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (4): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (model): ModelListGP(\n",
       "     (models): ModuleList(\n",
       "       (0): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "       (1): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "       (2): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "       (3): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "       (4): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "     (likelihood): LikelihoodList(\n",
       "       (likelihoods): ModuleList(\n",
       "         (0): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (1): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (2): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (3): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (4): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlls): ModuleList(\n",
       "     (0): ExactMarginalLogLikelihood(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (model): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "     (1): ExactMarginalLogLikelihood(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (model): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "     (2): ExactMarginalLogLikelihood(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (model): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "     (3): ExactMarginalLogLikelihood(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (model): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "     (4): ExactMarginalLogLikelihood(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (model): FixedNoiseGP(\n",
       "         (likelihood): FixedNoiseGaussianLikelihood(\n",
       "           (noise_covar): FixedGaussianNoise()\n",
       "         )\n",
       "         (mean_module): ConstantMean()\n",
       "         (covar_module): ScaleKernel(\n",
       "           (base_kernel): MaternKernel(\n",
       "             (lengthscale_prior): GammaPrior()\n",
       "             (raw_lengthscale_constraint): Positive()\n",
       "           )\n",
       "           (outputscale_prior): GammaPrior()\n",
       "           (raw_outputscale_constraint): Positive()\n",
       "         )\n",
       "         (outcome_transform): Standardize()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ModelListGP(\n",
       "   (models): ModuleList(\n",
       "     (0): FixedNoiseGP(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (mean_module): ConstantMean()\n",
       "       (covar_module): ScaleKernel(\n",
       "         (base_kernel): MaternKernel(\n",
       "           (lengthscale_prior): GammaPrior()\n",
       "           (raw_lengthscale_constraint): Positive()\n",
       "         )\n",
       "         (outputscale_prior): GammaPrior()\n",
       "         (raw_outputscale_constraint): Positive()\n",
       "       )\n",
       "       (outcome_transform): Standardize()\n",
       "     )\n",
       "     (1): FixedNoiseGP(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (mean_module): ConstantMean()\n",
       "       (covar_module): ScaleKernel(\n",
       "         (base_kernel): MaternKernel(\n",
       "           (lengthscale_prior): GammaPrior()\n",
       "           (raw_lengthscale_constraint): Positive()\n",
       "         )\n",
       "         (outputscale_prior): GammaPrior()\n",
       "         (raw_outputscale_constraint): Positive()\n",
       "       )\n",
       "       (outcome_transform): Standardize()\n",
       "     )\n",
       "     (2): FixedNoiseGP(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (mean_module): ConstantMean()\n",
       "       (covar_module): ScaleKernel(\n",
       "         (base_kernel): MaternKernel(\n",
       "           (lengthscale_prior): GammaPrior()\n",
       "           (raw_lengthscale_constraint): Positive()\n",
       "         )\n",
       "         (outputscale_prior): GammaPrior()\n",
       "         (raw_outputscale_constraint): Positive()\n",
       "       )\n",
       "       (outcome_transform): Standardize()\n",
       "     )\n",
       "     (3): FixedNoiseGP(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (mean_module): ConstantMean()\n",
       "       (covar_module): ScaleKernel(\n",
       "         (base_kernel): MaternKernel(\n",
       "           (lengthscale_prior): GammaPrior()\n",
       "           (raw_lengthscale_constraint): Positive()\n",
       "         )\n",
       "         (outputscale_prior): GammaPrior()\n",
       "         (raw_outputscale_constraint): Positive()\n",
       "       )\n",
       "       (outcome_transform): Standardize()\n",
       "     )\n",
       "     (4): FixedNoiseGP(\n",
       "       (likelihood): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (mean_module): ConstantMean()\n",
       "       (covar_module): ScaleKernel(\n",
       "         (base_kernel): MaternKernel(\n",
       "           (lengthscale_prior): GammaPrior()\n",
       "           (raw_lengthscale_constraint): Positive()\n",
       "         )\n",
       "         (outputscale_prior): GammaPrior()\n",
       "         (raw_outputscale_constraint): Positive()\n",
       "       )\n",
       "       (outcome_transform): Standardize()\n",
       "     )\n",
       "   )\n",
       "   (likelihood): LikelihoodList(\n",
       "     (likelihoods): ModuleList(\n",
       "       (0): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (1): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (2): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (3): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "       (4): FixedNoiseGaussianLikelihood(\n",
       "         (noise_covar): FixedGaussianNoise()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_model(X_torch, y_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n",
    "from botorch.acquisition.objective import GenericMCObjective\n",
    "from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import (\n",
    "    FastNondominatedPartitioning,\n",
    ")\n",
    "from botorch.acquisition.multi_objective.monte_carlo import (\n",
    "    qExpectedHypervolumeImprovement,\n",
    "    qNoisyExpectedHypervolumeImprovement,\n",
    ")\n",
    "from botorch.utils.sampling import sample_simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function(x):\n",
    "    '''return random number with shape of (n, len(target_col))'''\n",
    "    \n",
    "    return torch.rand(x.shape[0], len(target_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_RESTARTS = 10\n",
    "RAW_SAMPLES = 512\n",
    "\n",
    "ref_point = [0]*len(target_col)\n",
    "\n",
    "\n",
    "def optimize_qehvi_and_get_observation(model, train_x, train_obj, sampler):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    # partition non-dominated space into disjoint rectangles\n",
    "    with torch.no_grad():\n",
    "        pred = model.posterior(normalize(train_x, bounds)).mean\n",
    "    partitioning = FastNondominatedPartitioning(\n",
    "        ref_point=ref_point,\n",
    "        Y=pred,\n",
    "    )\n",
    "    acq_func = qExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=ref_point,\n",
    "        partitioning=partitioning,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=standard_bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        sequential=True,\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "    new_obj_true = dummy_function(new_x)\n",
    "    new_obj = new_obj_true + torch.randn_like(new_obj_true, 0.2)\n",
    "    return new_x, new_obj, new_obj_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.box_decompositions.dominated import (\n",
    "    DominatedPartitioning,\n",
    ")\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "N_BATCH = 20 \n",
    "MC_SAMPLES = 16\n",
    "\n",
    "verbose = True\n",
    "\n",
    "hvs_qehvi, hvs_random = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000e+02, 3.5000e+00, 1.0000e+00, 1.4050e+01, 1.1871e+02, 0.0000e+00],\n",
       "        [1.5000e+02, 3.3000e+00, 8.0000e-01, 1.4050e+01, 1.0768e+02, 2.0000e-01],\n",
       "        [1.5000e+02, 3.2000e+00, 5.0000e-01, 1.4050e+01, 9.1128e+01, 5.0000e-01],\n",
       "        [1.5000e+02, 3.1000e+00, 1.0000e-01, 1.4050e+01, 6.9062e+01, 9.0000e-01],\n",
       "        [1.5000e+02, 3.0000e+00, 5.0000e-02, 1.4050e+01, 6.6304e+01, 9.5000e-01],\n",
       "        [1.5000e+02, 3.0000e+00, 3.0000e-02, 1.4050e+01, 6.5201e+01, 9.7000e-01],\n",
       "        [1.5000e+02, 2.8000e+00, 0.0000e+00, 1.4050e+01, 6.3546e+01, 1.0000e+00],\n",
       "        [2.5000e+02, 4.0000e+00, 1.0000e+00, 1.4050e+01, 1.1871e+02, 0.0000e+00],\n",
       "        [2.5000e+02, 3.8000e+00, 8.0000e-01, 1.4050e+01, 1.0768e+02, 2.0000e-01],\n",
       "        [2.5000e+02, 3.7000e+00, 5.0000e-01, 1.4050e+01, 9.1128e+01, 5.0000e-01],\n",
       "        [2.5000e+02, 3.6000e+00, 1.0000e-01, 1.4050e+01, 6.9062e+01, 9.0000e-01],\n",
       "        [2.5000e+02, 3.6000e+00, 5.0000e-02, 1.4050e+01, 6.6304e+01, 9.5000e-01],\n",
       "        [2.5000e+02, 3.5000e+00, 3.0000e-02, 1.4050e+01, 6.5201e+01, 9.7000e-01],\n",
       "        [2.5000e+02, 3.2000e+00, 0.0000e+00, 1.4050e+01, 6.3546e+01, 1.0000e+00],\n",
       "        [3.5000e+02, 4.3000e+00, 1.0000e+00, 1.4050e+01, 1.1871e+02, 0.0000e+00],\n",
       "        [3.5000e+02, 4.2000e+00, 8.0000e-01, 1.4050e+01, 1.0768e+02, 2.0000e-01],\n",
       "        [3.5000e+02, 4.1000e+00, 5.0000e-01, 1.4050e+01, 9.1128e+01, 5.0000e-01],\n",
       "        [3.5000e+02, 4.1000e+00, 1.0000e-01, 1.4050e+01, 6.9062e+01, 9.0000e-01],\n",
       "        [3.5000e+02, 4.0000e+00, 5.0000e-02, 1.4050e+01, 6.6304e+01, 9.5000e-01],\n",
       "        [3.5000e+02, 4.0000e+00, 3.0000e-02, 1.4050e+01, 6.5201e+01, 9.7000e-01],\n",
       "        [3.5000e+02, 3.6000e+00, 0.0000e+00, 1.4050e+01, 6.3546e+01, 1.0000e+00],\n",
       "        [4.5000e+02, 4.7000e+00, 1.0000e+00, 1.4050e+01, 1.1871e+02, 0.0000e+00],\n",
       "        [4.5000e+02, 4.6000e+00, 8.0000e-01, 1.4050e+01, 1.0768e+02, 2.0000e-01],\n",
       "        [4.5000e+02, 4.6000e+00, 5.0000e-01, 1.4050e+01, 9.1128e+01, 5.0000e-01],\n",
       "        [4.5000e+02, 4.5000e+00, 1.0000e-01, 1.4050e+01, 6.9062e+01, 9.0000e-01],\n",
       "        [4.5000e+02, 4.5000e+00, 5.0000e-02, 1.4050e+01, 6.6304e+01, 9.5000e-01],\n",
       "        [4.5000e+02, 4.4000e+00, 3.0000e-02, 1.4050e+01, 6.5201e+01, 9.7000e-01],\n",
       "        [4.5000e+02, 4.2000e+00, 0.0000e+00, 1.4050e+01, 6.3546e+01, 1.0000e+00],\n",
       "        [1.4100e+02, 4.0000e+00, 1.0000e+00, 8.0200e+00, 1.1871e+02, 0.0000e+00],\n",
       "        [1.4300e+02, 4.0000e+00, 8.0000e-01, 8.0200e+00, 1.0768e+02, 2.0000e-01],\n",
       "        [1.4300e+02, 4.0000e+00, 5.0000e-01, 8.0200e+00, 9.1128e+01, 5.0000e-01],\n",
       "        [1.4500e+02, 4.0000e+00, 1.0000e-01, 8.0200e+00, 6.9062e+01, 9.0000e-01],\n",
       "        [1.4900e+02, 4.0000e+00, 5.0000e-02, 8.0200e+00, 6.6304e+01, 9.5000e-01],\n",
       "        [1.5000e+02, 4.0000e+00, 3.0000e-02, 8.0200e+00, 6.5201e+01, 9.7000e-01],\n",
       "        [1.5000e+02, 4.0000e+00, 0.0000e+00, 8.0200e+00, 6.3546e+01, 1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2300, 0.1200, 0.0000, 0.6100],\n",
       "        [0.0000, 0.2300, 0.0700, 0.0000, 0.6600],\n",
       "        [0.0000, 0.3400, 0.0500, 0.0300, 0.5200],\n",
       "        [0.0100, 0.4200, 0.0500, 0.0200, 0.4200],\n",
       "        [0.0400, 0.4800, 0.0500, 0.1000, 0.1900],\n",
       "        [0.0700, 0.5000, 0.0500, 0.1100, 0.1400],\n",
       "        [0.1500, 0.4700, 0.1100, 0.0600, 0.1100],\n",
       "        [0.0000, 0.2200, 0.1200, 0.0000, 0.6300],\n",
       "        [0.0000, 0.1700, 0.1000, 0.0000, 0.7000],\n",
       "        [0.0200, 0.3600, 0.0800, 0.0200, 0.4800],\n",
       "        [0.0600, 0.2300, 0.0700, 0.1200, 0.4200],\n",
       "        [0.0800, 0.1200, 0.0700, 0.3200, 0.2300],\n",
       "        [0.0900, 0.0500, 0.0600, 0.4800, 0.0900],\n",
       "        [0.3100, 0.1500, 0.1500, 0.1400, 0.0900],\n",
       "        [0.0000, 0.2200, 0.1200, 0.0000, 0.6300],\n",
       "        [0.0000, 0.1700, 0.1000, 0.0000, 0.7000],\n",
       "        [0.0200, 0.3600, 0.0800, 0.0200, 0.4800],\n",
       "        [0.0600, 0.2300, 0.0700, 0.1200, 0.4200],\n",
       "        [0.0800, 0.1200, 0.0700, 0.3200, 0.2300],\n",
       "        [0.0900, 0.0500, 0.0600, 0.4800, 0.0900],\n",
       "        [0.3100, 0.1500, 0.1500, 0.1400, 0.0900],\n",
       "        [0.0000, 0.1800, 0.3700, 0.0000, 0.3300],\n",
       "        [0.0000, 0.1000, 0.3200, 0.0000, 0.5000],\n",
       "        [0.0200, 0.1900, 0.3300, 0.0200, 0.3900],\n",
       "        [0.0300, 0.1000, 0.3000, 0.0700, 0.3700],\n",
       "        [0.0600, 0.1000, 0.2900, 0.2100, 0.1400],\n",
       "        [0.1000, 0.0500, 0.2700, 0.2600, 0.0900],\n",
       "        [0.2500, 0.0900, 0.2800, 0.1100, 0.0800],\n",
       "        [0.0000, 0.2200, 0.1600, 0.0000, 0.5900],\n",
       "        [0.0000, 0.1900, 0.1300, 0.0000, 0.6200],\n",
       "        [0.0100, 0.2700, 0.1000, 0.0200, 0.5600],\n",
       "        [0.1100, 0.3300, 0.1000, 0.0400, 0.3800],\n",
       "        [0.2100, 0.2800, 0.1000, 0.1400, 0.1900],\n",
       "        [0.2400, 0.1800, 0.0900, 0.2500, 0.1400],\n",
       "        [0.3700, 0.1300, 0.1700, 0.1100, 0.0700]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/MatML/lib/python3.8/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "# intialize model\n",
    "mll_qehvi, model_qehvi = initialize_model(X_torch, y_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SumMarginalLogLikelihood(\n",
       "  (likelihood): LikelihoodList(\n",
       "    (likelihoods): ModuleList(\n",
       "      (0): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (1): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (2): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (3): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (4): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model): ModelListGP(\n",
       "    (models): ModuleList(\n",
       "      (0): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "      (1): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "      (2): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "      (3): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "      (4): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "    (likelihood): LikelihoodList(\n",
       "      (likelihoods): ModuleList(\n",
       "        (0): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (1): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (2): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (3): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (4): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlls): ModuleList(\n",
       "    (0): ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "    (1): ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "    (2): ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "    (3): ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "    (4): ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): FixedNoiseGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): ScaleKernel(\n",
       "          (base_kernel): MaternKernel(\n",
       "            (lengthscale_prior): GammaPrior()\n",
       "            (raw_lengthscale_constraint): Positive()\n",
       "          )\n",
       "          (outputscale_prior): GammaPrior()\n",
       "          (raw_outputscale_constraint): Positive()\n",
       "        )\n",
       "        (outcome_transform): Standardize()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll_qehvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_qehvi, train_obj_qehvi, train_obj_true_qehvi = (\n",
    "    X_torch,\n",
    "    train_obj_qparego,\n",
    "    train_obj_true_qparego,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/MatML/lib/python3.8/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m mll_qehvi, model_qehvi \u001b[38;5;241m=\u001b[39m initialize_model(X_torch, y_torch)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# compute hypervolume\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m bd \u001b[38;5;241m=\u001b[39m \u001b[43mDominatedPartitioning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_torch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m volume \u001b[38;5;241m=\u001b[39m bd\u001b[38;5;241m.\u001b[39mcompute_hypervolume()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m hvs_qehvi\u001b[38;5;241m.\u001b[39mappend(volume)\n",
      "File \u001b[0;32m~/miniconda3/envs/MatML/lib/python3.8/site-packages/botorch/utils/multi_objective/box_decompositions/box_decomposition.py:274\u001b[0m, in \u001b[0;36mFastPartitioning.__init__\u001b[0;34m(self, ref_point, Y)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    266\u001b[0m     ref_point: Tensor,\n\u001b[1;32m    267\u001b[0m     Y: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m        ref_point: A `m`-dim tensor containing the reference point.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        Y: A `(batch_shape) x n x m`-dim tensor\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(ref_point\u001b[38;5;241m=\u001b[39mref_point, Y\u001b[38;5;241m=\u001b[39mY, sort\u001b[38;5;241m=\u001b[39m\u001b[43mref_point\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute hypervolume\n",
    "bd = DominatedPartitioning(ref_point=ref_point, Y=y_torch)\n",
    "volume = bd.compute_hypervolume().item()\n",
    "\n",
    "hvs_qehvi.append(volume)\n",
    "hvs_random.append(volume)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "for iteration in range(1, N_BATCH + 1):\n",
    "\n",
    "    t0 = time.monotonic()\n",
    "\n",
    "    # fit the models\n",
    "    fit_gpytorch_mll(mll_qparego)\n",
    "    fit_gpytorch_mll(mll_qehvi)\n",
    "    fit_gpytorch_mll(mll_qnehvi)\n",
    "\n",
    "    # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "    qparego_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    qehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    qnehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "\n",
    "    # optimize acquisition functions and get new observations\n",
    "    (\n",
    "        new_x_qparego,\n",
    "        new_obj_qparego,\n",
    "        new_obj_true_qparego,\n",
    "    ) = optimize_qnparego_and_get_observation(\n",
    "        model_qparego, train_x_qparego, train_obj_qparego, qparego_sampler\n",
    "    )\n",
    "    new_x_qehvi, new_obj_qehvi, new_obj_true_qehvi = optimize_qehvi_and_get_observation(\n",
    "        model_qehvi, train_x_qehvi, train_obj_qehvi, qehvi_sampler\n",
    "    )\n",
    "    (\n",
    "        new_x_qnehvi,\n",
    "        new_obj_qnehvi,\n",
    "        new_obj_true_qnehvi,\n",
    "    ) = optimize_qnehvi_and_get_observation(\n",
    "        model_qnehvi, train_x_qnehvi, train_obj_qnehvi, qnehvi_sampler\n",
    "    )\n",
    "    new_x_random, new_obj_random, new_obj_true_random = generate_initial_data(\n",
    "        n=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # update training points\n",
    "    train_x_qparego = torch.cat([train_x_qparego, new_x_qparego])\n",
    "    train_obj_qparego = torch.cat([train_obj_qparego, new_obj_qparego])\n",
    "    train_obj_true_qparego = torch.cat([train_obj_true_qparego, new_obj_true_qparego])\n",
    "\n",
    "    train_x_qehvi = torch.cat([train_x_qehvi, new_x_qehvi])\n",
    "    train_obj_qehvi = torch.cat([train_obj_qehvi, new_obj_qehvi])\n",
    "    train_obj_true_qehvi = torch.cat([train_obj_true_qehvi, new_obj_true_qehvi])\n",
    "\n",
    "    train_x_qnehvi = torch.cat([train_x_qnehvi, new_x_qnehvi])\n",
    "    train_obj_qnehvi = torch.cat([train_obj_qnehvi, new_obj_qnehvi])\n",
    "    train_obj_true_qnehvi = torch.cat([train_obj_true_qnehvi, new_obj_true_qnehvi])\n",
    "\n",
    "    train_x_random = torch.cat([train_x_random, new_x_random])\n",
    "    train_obj_random = torch.cat([train_obj_random, new_obj_random])\n",
    "    train_obj_true_random = torch.cat([train_obj_true_random, new_obj_true_random])\n",
    "\n",
    "    # update progress\n",
    "    for hvs_list, train_obj in zip(\n",
    "        (hvs_random, hvs_qparego, hvs_qehvi, hvs_qnehvi),\n",
    "        (\n",
    "            train_obj_true_random,\n",
    "            train_obj_true_qparego,\n",
    "            train_obj_true_qehvi,\n",
    "            train_obj_true_qnehvi,\n",
    "        ),\n",
    "    ):\n",
    "        # compute hypervolume\n",
    "        bd = DominatedPartitioning(ref_point=problem.ref_point, Y=train_obj)\n",
    "        volume = bd.compute_hypervolume().item()\n",
    "        hvs_list.append(volume)\n",
    "\n",
    "    # reinitialize the models so they are ready for fitting on next iteration\n",
    "    # Note: we find improved performance from not warm starting the model hyperparameters\n",
    "    # using the hyperparameters from the previous iteration\n",
    "    mll_qparego, model_qparego = initialize_model(train_x_qparego, train_obj_qparego)\n",
    "    mll_qehvi, model_qehvi = initialize_model(train_x_qehvi, train_obj_qehvi)\n",
    "    mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi)\n",
    "\n",
    "    t1 = time.monotonic()\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"\\nBatch {iteration:>2}: Hypervolume (random, qNParEGO, qEHVI, qNEHVI) = \"\n",
    "            f\"({hvs_random[-1]:>4.2f}, {hvs_qparego[-1]:>4.2f}, {hvs_qehvi[-1]:>4.2f}, {hvs_qnehvi[-1]:>4.2f}), \"\n",
    "            f\"time = {t1-t0:>4.2f}.\",\n",
    "            end=\"\",\n",
    "        )\n",
    "    else:\n",
    "        print(\".\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMPUTE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
